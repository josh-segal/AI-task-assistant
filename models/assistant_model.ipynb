{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import create_optimizer, AutoTokenizer, DataCollatorWithPadding, TFAutoModelForSequenceClassification\n",
    "from transformers.keras_callbacks import KerasMetricCallback, PushToHubCallback\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## load dataset\n",
    "df = pd.read_csv('intent_classification_task_data.csv')\n",
    "\n",
    "## preprocess into list of strings\n",
    "task_list = []\n",
    "label_list = []\n",
    "\n",
    "for text, label  in zip(df[\"text\"], df[\"label\"]):\n",
    "    task_list.append(text)\n",
    "    label_list.append(label)\n",
    "\n",
    "## process into Hugging Face Dataset\n",
    "data = {\n",
    "    \"label\": label_list,\n",
    "    \"text\": task_list\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id2label = {0: \"Event\", 1: \"Reminder\", 2: \"Todo\"}\n",
    "label2id = {\"Event\": 0, \"Reminder\": 1, \"Todo\": 2}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## change labels to id encoding\n",
    "labels = []\n",
    "for label in data[\"label\"]:\n",
    "    labels.append(label2id[label])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## split into train and test sets with labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"text\"], labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_text = []\n",
    "test_text = []\n",
    "train_label = []\n",
    "test_label = []\n",
    "\n",
    "for text, label in zip(X_train, y_train):\n",
    "    train_text.append(text)\n",
    "    train_label.append(label)\n",
    "\n",
    "for text, label in zip(X_test, y_test):\n",
    "    test_text.append(text)\n",
    "    test_label.append(label)\n",
    "\n",
    "train_dict = {\n",
    "    \"label\": train_label,\n",
    "    \"text\": train_text\n",
    "}\n",
    "\n",
    "test_dict = {\n",
    "    \"label\": test_label,\n",
    "    \"text\": test_text\n",
    "}\n",
    "\n",
    "train_data = Dataset.from_dict(train_dict)\n",
    "test_data = Dataset.from_dict(test_dict)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## distilBERT tokenizer to preprocess\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## preprocessing function to apply tokenizer over whole dataset\n",
    "def preprocess_function(data):\n",
    "    return tokenizer(data[\"text\"], truncation=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## batch to process multiple at once for faster compute\n",
    "tokenized_train_data = train_data.map(preprocess_function, batched=True)\n",
    "tokenized_test_data = test_data.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## padding dynamically\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## metrics function that passes preds and labels to compute metrics\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 5\n",
    "batches_per_epoch = len(train_data) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "# try 3e-5\n",
    "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=3, id2label=id2label, label2id=label2id)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    tokenized_train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_test_set = model.prepare_tf_dataset(\n",
    "    tokenized_test_data,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer) #Transformer has default task-relevant loss function\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_test_set)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir=\"assistant\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "callbacks = [metric_callback, push_to_hub_callback]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=3, callbacks=callbacks)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
